# ğŸŒ³ Decision Tree Classifier from Scratch (Information Gain & Entropy)

This project demonstrates how to build a **Decision Tree Classifier from scratch** using core concepts of **Entropy** and **Information Gain** â€” fundamental to Machine Learning.

Unlike typical models built using libraries like `scikit-learn`, this notebook manually constructs a decision tree using custom Python functions and visualizes it using `Graphviz`.

---

## ğŸ§  Key Concepts Used

### ğŸ“˜ Entropy
Entropy measures the randomness in the data. A lower entropy indicates better classification.

### ğŸ“˜ Information Gain
Information Gain measures the reduction in entropy achieved by splitting the dataset on a particular attribute.

---

## ğŸ› ï¸ Technologies Used

- Python
- Pandas â€“ for data manipulation
- Math â€“ for entropy/log calculations
- Graphviz â€“ for visualizing the tree
- Jupyter Notebook

---

## ğŸ—ƒï¸ Dataset Used

The dataset is a small, manually created DataFrame representing customer decisions about purchasing a computer, with features like:

| Age         | Income | Student | Buy Computer |
|-------------|--------|---------|--------------|
| Young       | High   | Yes     | Yes          |
| Young       | High   | No      | No           |
| Middle-aged | Low    | No      | Yes          |
| Old         | Medium | Yes     | No           |
| Old         | High   | Yes     | Yes          |
| Old         | Low    | No      | No           |

---

## ğŸš€ How It Works

1. **Calculate Entropy** of the dataset.
2. **Compute Information Gain** for each attribute.
3. **Select the best attribute** (with highest gain) for splitting.
4. **Recursively split** subsets until:
   - All records belong to a single class.
   - No attributes are left.
5. **Render Tree** using Graphviz.

---

## ğŸ“ˆ Output

The final output is a **visual decision tree** saved as a PNG image:

```
Root
 â”œâ”€â”€ Age = Young
 â”‚    â””â”€â”€ ...
 â”œâ”€â”€ Age = Old
 â”‚    â””â”€â”€ ...
 â””â”€â”€ Age = Middle-aged
      â””â”€â”€ ...
```

You can view the tree image generated as `decision_tree.png`.

---

## ğŸ“¦ How to Run This Project

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/decision-tree-from-scratch.git
   cd decision-tree-from-scratch
   ```

2. Install dependencies:
   ```bash
   pip install pandas graphviz
   ```

3. Run the Jupyter Notebook:
   ```bash
   jupyter notebook "Project - 9.ipynb"
   ```

4. Make sure Graphviz is installed in your system. On Windows, you can download it from:  
   ğŸ‘‰ https://graphviz.gitlab.io/_pages/Download/Download_windows.html

---

## ğŸ™‹â€â™‚ï¸ Why This Project?

This project helps you:
- Understand how decision trees **actually work under the hood**.
- Get familiar with **Entropy**, **Information Gain**, and **recursion**.
- Visualize models using **Graphviz**, which is a widely used tool for decision trees.

---

## ğŸ§¾ License

This project is licensed under the **MIT License** â€“ use it freely!

---

## ğŸ¤ Contributions Welcome

If you'd like to extend the tree builder or test it on a larger dataset, feel free to contribute!
